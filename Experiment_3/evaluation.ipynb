{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import json\n",
    "\n",
    "def read_json_file(file_name):\n",
    "    #input tweet.txt\n",
    "    #output tweet_id_set\n",
    "    with open(file_name, 'r', errors='ignore') as f:\n",
    "         tweet_id_set = set()\n",
    "         for line in f:\n",
    "            json_obj = json.loads(line.strip())\n",
    "            tweetid = json_obj['tweetId']\n",
    "            tweet_id_set.add(tweetid)\n",
    "    return tweet_id_set\n",
    "\n",
    "def filer_qrels_file(file_name, out_file_name, tweet_id_set):\n",
    "    with open(out_file_name, 'w', encoding='utf-8') as f_out:\n",
    "        with open(file_name, 'r', errors='ignore') as f_in:\n",
    "            for line in f_in:\n",
    "                ele = line.strip().split(' ')\n",
    "                if ele[2] in tweet_id_set:\n",
    "                    f_out.write(line)\n",
    "\n",
    "def query_result_simulation(file_name, out_file_name, tweet_id_set):\n",
    "    with open(out_file_name, 'w', encoding='utf-8') as f_out:\n",
    "        with open(file_name, 'r', errors='ignore') as f_in:\n",
    "            for line in f_in:\n",
    "                ele = line.strip().split(' ')\n",
    "                # if ele[2] in tweet_id_set and int(ele[3]) > 0:\n",
    "                if ele[2] in tweet_id_set:\n",
    "                    f_out.write(' '.join([ele[0], ele[2]]) + '\\n')\n",
    "\n",
    "def filter_out_of_set():\n",
    "    id_file = 'tweets.txt'\n",
    "    in_file = 'qrels2014.txt'\n",
    "    out_file = 'qrels.txt'\n",
    "    sim_file = 'result.txt'\n",
    "    tweet_id_set = read_json_file(id_file)\n",
    "    print(len(tweet_id_set))\n",
    "    # remove unrelated ids\n",
    "    # filer_qrels_file(in_file, out_file, tweet_id_set)\n",
    "    # generate simulate test_set\n",
    "    query_result_simulation(in_file, sim_file, tweet_id_set)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    filter_out_of_set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def generate_tweetid_gain(file_name):\n",
    "    qrels_dict = {}\n",
    "    with open(file_name, 'r', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            ele = line.strip().split(' ')\n",
    "            if ele[0] not in qrels_dict:\n",
    "                qrels_dict[ele[0]] = {}\n",
    "            # here we want the gain of doc_id in qrels_dict > 0,\n",
    "            # so it's sorted values can be IDCG groundtruth\n",
    "            if int(ele[3]) > 0:\n",
    "                qrels_dict[ele[0]][ele[2]] = int(ele[3])\n",
    "    return qrels_dict\n",
    "\n",
    "def read_tweetid_test(file_name):\n",
    "    # input file format\n",
    "    # query_id doc_id\n",
    "    # query_id doc_id\n",
    "    # query_id doc_id\n",
    "    # ...\n",
    "    test_dict = {}\n",
    "    with open(file_name, 'r', errors='ignore') as f:\n",
    "        for line in f:\n",
    "            ele = line.strip().split(' ')\n",
    "            if ele[0] not in test_dict:\n",
    "                test_dict[ele[0]] = []\n",
    "            test_dict[ele[0]].append(ele[1])\n",
    "    return test_dict\n",
    "\n",
    "#qrels_dict是真实情况 test_dict是查询的结果\n",
    "def MAP_eval(qrels_dict, test_dict, k = 100):\n",
    "    #每个quel的precision的平均\n",
    "    map_list = []\n",
    "    for quel in qrels_dict:\n",
    "        k_list = []\n",
    "        for r in range(len(test_dict[quel][:])):\n",
    "            related_num = 0\n",
    "            for i in test_dict[quel][:r]:\n",
    "                if i in qrels_dict[quel]:\n",
    "                    related_num += 1\n",
    "            k_list.append(related_num/len(test_dict[quel][:]))\n",
    "        map_list.append(np.mean(np.array(k_list)))\n",
    "    return np.mean(np.array(map_list))\n",
    "\n",
    "def MRR_eval(qrels_dict, test_dict, k = 100):\n",
    "    K_list = []\n",
    "    for quel in qrels_dict:\n",
    "        First_doc = list(qrels_dict[quel].keys())[0]\n",
    "        K = test_dict[quel].index(First_doc)\n",
    "        K_list.append(K)\n",
    "    return np.mean(1/(np.array(K_list)+1))\n",
    "\n",
    "def NDCG_eval(qrels_dict, test_dict, k = 100):\n",
    "    NDCG = []\n",
    "    for quel in qrels_dict:\n",
    "        rel = []\n",
    "        i = np.arange(1,k+1)\n",
    "        for j in test_dict[quel][:k]:\n",
    "            try:\n",
    "                rel.append(qrels_dict[quel][j])\n",
    "            except KeyError:\n",
    "                rel.append(0)        \n",
    "        i = np.arange(1,min(len(test_dict[quel][:]),k)+1)\n",
    "        DCG_list = np.array(rel)/np.log2(i+1)#不能是0\n",
    "        DCG = np.sum(DCG_list)\n",
    "        sorted_list = [i for i in list(qrels_dict[quel].keys()) if qrels_dict[quel][i] == 2] +\\\n",
    "        [i for i in list(qrels_dict[quel].keys()) if qrels_dict[quel][i] == 1]\n",
    "        \n",
    "        IDCG_rel = []\n",
    "        for j in sorted_list:\n",
    "            IDCG_rel.append(qrels_dict[quel][j])\n",
    "        I = np.arange(1,len(sorted_list)+1)\n",
    "        IDCG_list = np.array(IDCG_rel)/np.log2(I+1)#不能是0\n",
    "        IDCG = np.sum(IDCG_list)\n",
    "        NDCG.append(DCG/IDCG)\n",
    "    return np.mean(np.array(NDCG))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation():\n",
    "    k = 100\n",
    "    # query relevance file\n",
    "    file_qrels_path = 'qrels.txt'\n",
    "    # qrels_dict = {query_id:{doc_id:gain, doc_id:gain, ...}, ...}\n",
    "    qrels_dict = generate_tweetid_gain(file_qrels_path)\n",
    "    # ur result, format is in function read_tweetid_test, or u can write by ur own\n",
    "    file_test_path = 'result.txt'\n",
    "    # test_dict = {query_id:[doc_id, doc_id, ...], ...}\n",
    "    test_dict = read_tweetid_test(file_test_path)\n",
    "\n",
    "    MAP = MAP_eval(qrels_dict, test_dict, k)\n",
    "    print('MAP', ' = ', MAP, sep='')\n",
    "    \n",
    "    MRR = MRR_eval(qrels_dict, test_dict, k)\n",
    "    print('MRR', ' = ', MRR, sep='')\n",
    "\n",
    "    NDCG = NDCG_eval(qrels_dict, test_dict, k)\n",
    "    print('NDCG', ' = ', NDCG, sep='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAP = 0.4264352262227257\n",
      "MRR = 0.79737012987013\n",
      "NDCG = 0.6875441733398155\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    evaluation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
